# Data-Collection-Pipeline

Answer some of these questions in the next few bullet points. What have you built? What technologies have you used? Why have you used those?

Milestone 1
- I decided to scrape the Instagram website. I want to create a scraper bot that is able to get the links of the most recent posts and using this, retrieve the comments.

Milestone 2
- I have written code using selenium in order to perform certain actions automatically.
    - Accepting cookies: When loading the instagram website, a pop up appears saying to accept cookies. So, I have written code in order to automatically accept cookies.
    - Saving information: Another popup which asks the user to save login information appears so if accepted, the user does not have to login with their user name and password next time. So I have written code in order to bypass this.
    - Login: In order to navigate through the instagram website, a user has to login. I have hard coded my username and password in the code that I have written, so it will automatically enter in a username and password and click on the "login" button.

Milestone 3
- function to retirve text (scraping comments)
- UUID for unique ID for an entry
- Unique values (convert to set)
- Talk about the methods you have added and the reasoning behind your approach.
Milestone 4
- creating unit tests
- how testing works for your scraper
Milestone 5
- Talk about the cloud services you have used and how you interact with them in your code using boto3.
Milestone 7
- Talk about docker and how it works, your code refactorisation and the techniques you used to avoid rescraping data.
Milestone 8
- talk about prometheus and grafana
Milestone 9
- Talk about CI/CD pipelines and the process you have developed.
